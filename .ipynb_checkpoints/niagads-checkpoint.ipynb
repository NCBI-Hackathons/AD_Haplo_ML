{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to join all of the different datasets into one giant matrix which can then be fed into the autoencoder. To start, let's look at each dataset that we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -n 10 ng00061/WES_release3AtlasOnly_vep80_most_severe_consequence_per_gene.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# These have different numbers of columns of course. Need to fix this maybe? Will only use the coordinates from this\n",
    "# for now, this is the primary key to link all the other datasets.\n",
    "head -n 10 ng00061/WES_release3AtlasOnly_rolling_flat_annotation.txt\n",
    "cut -f1-5 WGS_v1_rolling_flat_annotation.txt > WGS_v1_rolling_flat_annotation.pos_only.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -n 10 ../IGAP_summary_statistics/IGAP_stage_1_2_combined.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# I will join all of the chromosomes into one file.\n",
    "cat /home/twaddlac/Hackthan_AD/ng00039/pvalue_only/metaanalysis/pvalueonly_METAANALYSIS1_chr*.TBL | perl -pe 's/^(\\d+)-(\\d+)/$1\\t$2/g' > pvalue_only.tsv\n",
    "head -n 10 ../pvalue_only.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hap300_CER_AD.txt\n",
      "Hap300_CER_All.txt\n",
      "Hap300_CER_Control.txt\n",
      "Hap300_TX_AD.txt\n",
      "Hap300_TX_All.txt\n",
      "Hap300_TX_Control.txt\n",
      "HapMap2_CER_AD.txt\n",
      "HapMap2_CER_All.txt\n",
      "HapMap2_CER_Control.txt\n",
      "HapMap2_TX_AD.txt\n",
      "HapMap2_TX_All.txt\n",
      "HapMap2_TX_Control.txt\n",
      "README_Brain_eGWAS_files_06-05-2012.doc\n",
      "CHR\tSNP\tBP\tA1\tTEST\tNMISS\tBETA\tSTAT\tP\tPROBE\ttxStart\ttxEnd\tSYMBOL\thasSNP\n",
      "11\trs11552421\t117935729\tA\tADD\t373\t2.6680000000000001\t46.130000000000003\t3.4999999999999998E-153\tILMN_1651745\t117907012\t117922523\tTMEM25\tFalse\n",
      "11\trs17742\t117978595\tG\tADD\t373\t2.6920000000000002\t44.960000000000001\t9.2029999999999997E-150\tILMN_1651745\t117907012\t117922523\tTMEM25\tFalse\n",
      "5\trs3776455\t7949511\tG\tADD\t373\t1.2030000000000001\t39.5\t6.3720000000000003E-133\tILMN_1718932\t7922216\t7954235\tMTRR\tTrue\n",
      "6\trs1096699\t43636419\tA\tADD\t372\t1.256\t34.659999999999997\t1.4079999999999999E-116\tILMN_1694711\t43711554\t43716666\tMAD2L1BP\tFalse\n",
      "12\trs10843881\t31132612\tG\tADD\t373\t-1.0600000000000001\t-33.469999999999999\t1.481E-112\tILMN_2345908\t31118045\t31148992\tDDX11\tTrue\n",
      "12\trs2708389\t11096007\tG\tADD\t366\t1.073\t33.68\t2.8000000000000002E-112\tILMN_1730477\t11135152\t11136179\tTAS2R43\tFalse\n",
      "12\trs4031375\t31105446\tG\tADD\t357\t-1.048\t-33.039999999999999\t9.297E-109\tILMN_2345908\t31118045\t31148992\tDDX11\tTrue\n",
      "6\trs1617105\t43721158\tA\tADD\t357\t1.244\t32.280000000000001\t3.8799999999999999E-106\tILMN_1694711\t43711554\t43716666\tMAD2L1BP\tFalse\n",
      "12\trs1376250\t11056661\tA\tADD\t363\t-1.0629999999999999\t-31.649999999999999\t1.021E-104\tILMN_1730477\t11135152\t11136179\tTAS2R43\tFalse\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#I'm not sure what the difference is between these but I am assuming we get the inverse of controls here.\n",
    "# We will use the controls for a confusion matrix\n",
    "ls /data/Hackthan_AD/Mayo_eGWAS/\n",
    "head /data/Hackthan_AD/Mayo_eGWAS/Hap300_CER_All.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "igap1 = pd.read_csv('/data/Hackthan_AD/IGAP_summary_statistics/IGAP_stage_1.txt', sep='\\t')\n",
    "igap12 = pd.read_csv('/data/Hackthan_AD/IGAP_summary_statistics/IGAP_stage_1_2_combined.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Only going to use the coordinates of the annotation files since they have mismatching columns.\n",
    "##### Only run this once #####\n",
    "#cut -f1-5 /data/Hackthan_AD/NG00061/WGS_v1_rolling_flat_annotation.txt > /data/Hackthan_AD/NG00061/WGS_v1_rolling_flat_annotation.pos_only.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno = pd.read_csv('/data/Hackthan_AD/NG00061/WGS_v1_rolling_flat_annotation.pos_only.txt', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conseq = pd.read_csv('/data/Hackthan_AD/NG00061/WGS_v1_vep80_most_severe_consequence_per_gene.txt', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "## only need to run once\n",
    "cat <(grep -m1 '^Marker' /home/twaddlac/Hackthan_AD/ng00039/pvalue_only/pvalue/pvalueonly_METAANALYSIS1_chr10.TBL) <(cat /home/twaddlac/Hackthan_AD/ng00039/pvalue_only/pvalue/*TBL | perl -pe 's/(\\d+)-(\\d+)/$1\\t$2/g'| grep -v '^Marker') > /home/twaddlac/Hackthan_AD/ng00039/pvalue_only/pvalue/pvalue.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue = pd.read_csv('/home/twaddlac/Hackthan_AD/ng00039/pvalue_only/pvalue/pvalue.tsv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hap300ad = pd.read_csv('/home/twaddlac/Hackthan_AD/Hap300_CER_AD.txt', sep='\\t', header=0)\n",
    "hap300ad = pd.read_csv('/home/twaddlac/Hackthan_AD/Hap300_TX_AD.txt', sep='\\t', header=0)\n",
    "hap300ad = pd.read_csv('/home/twaddlac/Hackthan_AD/Hap300_CER_AD.txt', sep='\\t', header=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
